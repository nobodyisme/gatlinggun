#!/usr/bin/env python
from ConfigParser import ConfigParser
from multiprocessing import Process
import os.path
import sys
import time

from kazoo.client import KazooClient
from mastermind.utils.queue import LockingQueue
import msgpack
from opster import command
import tornado
from tornado import web

from gatlinggun.config import JsonConfig
from gatlinggun import daemon
from gatlinggun.errors import ConnectionError, InvalidDataError
from gatlinggun.gun import Gun
from gatlinggun import helpers as h
from gatlinggun.logger import logger, setup_logger
# from gatlinggun.mastermind_client import ReconnectableService
from gatlinggun import monitor
from gatlinggun import sync


DEFAULT_LOGGING_CONFIG_PATH = '/etc/elliptics/gatlinggun/logging-default.conf'
LOGGING_CONFIG_PATH = '/etc/elliptics/gatlinggun/logging.conf'

DEFAULT_PIDFILE = '/var/run/elliptics-gatlinggun/gatlinggun'


@command(usage='-c CONFIG -l LOGGING_CONFIG'
               '[--daemonize] [--pidfile PIDFILE] [--user USER]')
def main(config=('c', '', 'Application config file'),
         log_config=('l', '', 'Application logging config file'),
         daemonize=('', False, 'Daemonize this process'),
         pidfile=('', None, 'Use this pidfile'),
         user=('', None, '')):
    """This script starts gatling gun daemon that
    distributes keys to designated cache nodes"""

    main_config = ConfigParser({'read_chunk_size': None,
                                'write_chunK_size': None})

    if not config:
        raise RuntimeError('Application config is required (-c|--config)')

    if not main_config.read(config):
        raise RuntimeError('Failed to open config file: {0}'.format(config))

    use_log_config = DEFAULT_LOGGING_CONFIG_PATH
    if log_config:
        use_log_config = log_config
    elif os.path.exists(LOGGING_CONFIG_PATH):
        use_log_config = LOGGING_CONFIG_PATH

    try:
        if daemonize:
            user = user or main_config.get('global', 'user')
            d = daemon.Daemon(pidfile or DEFAULT_PIDFILE, user)
            d.run = run
            d.start(main_config, use_log_config)
        else:
            run(main_config, use_log_config)
    except Exception as e:
        logger.exception('Main process failed: {0}'.format(e))
        sys.exit(1)


def run(config, log_config):
    logging_config = JsonConfig(log_config)
    setup_logger(logging_config['logging'])

    if config.has_option('global', 'monitor_port'):
        p = Process(target=monitor_app, args=(config,))
        p.start()

    node = h.make_elliptics_node(config)

    gun = Gun(
        node,
        config.get('elliptics', 'cache_path_prefix'),
        config.get('global', 'tmp_dir'),
        read_size_chunk=config.get('elliptics', 'read_chunk_size'),
        write_size_chunk=config.get('elliptics', 'write_chunk_size'))
    zk_addresses = config.get('zookeeper', 'addresses')
    logger.info('Connection to transport hosts %s' % zk_addresses)
    if isinstance(zk_addresses, unicode):
        zk_addresses = zk_addresses.encode('utf-8')
    client = KazooClient(zk_addresses)
    client.start()
    task_queues = [LockingQueue(client, config.get('zookeeper', 'task_path'), group_id)
                   for group_id in gun.local_cache_groups]
    # transport = Transport(gun.local_cache_groups,
    #     config.get('zookeeper', 'task_path'),
    #     host=zk_addresses, timeout=3)

    sync.PeriodThread(gun.update_local_cache_groups,
                      config.getint('global', 'sync_keys_period')
                      if config.has_option('global', 'sync_keys_period') else
                      10
    ).start()

    # mastermind = ReconnectableService(
    #     config.get('mastermind', 'app'),
    #     config.get('mastermind', 'addresses')
    # )
    # synchronizer = sync.Synchronizer(node, group, transport, service)
    # pth = sync.PeriodThread(synchronizer.sync_keys,
    #                         config.getint('global', 'sync_keys_period')).start()

    logger.info('Starting task processing')

    while True:
        logger.info('Fetching task from queue')

        for task_queue in task_queues:
            try:
                for item in task_queue:
                    try:
                        task = msgpack.unpackb(item.data)

                        logger.info('Task %s fetched' % task['key'])
                        logger.debug('Task %s: %s' % (task['key'], task))
                        gun.process(task)
                        logger.info('Task %s processed' % (task['key'],))
                        item.consume()

                    except ConnectionError as e:
                        logger.exception(e)

                    except InvalidDataError as e:
                        logger.error(e)
                        try:
                            item.consume()
                        except Exception as e:
                            logger.error('Failed to consume item: {}'.format(e))
                            pass

            except Exception as e:
                logger.exception(e)

            finally:
                time.sleep(1)


def monitor_app(config):
    mon = monitor.Monitor(config)
    application = web.Application([
        (r"/stats/", monitor.MonitorHandler, {'monitor': mon})
    ], gzip=True)
    application.listen(config.get('global', 'monitor_port'))
    tornado.ioloop.IOLoop.instance().start()


if __name__ == '__main__':
    main.command()
